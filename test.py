from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

enhanced_Interaction_Customer_Transaction_Login = pd.read_csv("enhanced_customer_data.csv")
from ctgan import CTGAN
import pandas as pd
from tqdm import tqdm  # å¼•å…¥è¿›åº¦æ¡
import time

from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import networkx as nx
from collections import defaultdict
import plotly.graph_objects as go
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from xgboost import XGBClassifier
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA  

os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
# ==============================
# 1ï¸âƒ£  åŠ è½½åŸå§‹æ•°æ®
# ==============================
data = enhanced_Interaction_Customer_Transaction_Login.copy()

# ==============================
# 2ï¸âƒ£  é€‰æ‹©éœ€è¦å¢å¼ºçš„æ•°æ®ï¼ˆå¯é€‰æ‹© ChurnStatus = 1 çš„æ•°æ®ï¼‰
# ==============================
data_to_augment = data[data['ChurnStatus'] == 1]  # åªå¢å¼ºæµå¤±ç”¨æˆ·æ•°æ®
num_samples = len(data_to_augment) * 5  # ç”Ÿæˆäº”å€çš„æµå¤±æ•°æ®

# ==============================
# 3ï¸âƒ£  è®­ç»ƒ CTGAN æ¨¡å‹ï¼ˆæ·»åŠ è¿›åº¦æ¡ï¼‰
# ==============================
epochs = 500  # è®­ç»ƒ 300 è½®

# åˆ›å»º CTGAN æ¨¡å‹
ctgan = CTGAN(epochs=epochs, batch_size=500, verbose=False)  

# ä½¿ç”¨ tqdm åŒ…è£…è®­ç»ƒè¿‡ç¨‹
print("Training CTGAN...")
for epoch in tqdm(range(epochs), desc="CTGAN Training Progress"):
    
    ctgan.fit(data_to_augment)  

print("CTGAN Training Complete!")

# ==============================
# 4ï¸âƒ£  ç”Ÿæˆæ–°çš„åˆæˆæ•°æ®
# ==============================
print("ğŸ”„ Generating synthetic data...")
new_data = ctgan.sample(num_samples)

# ç¡®ä¿æ•°æ®ç±»å‹åŒ¹é…
for col in data_to_augment.columns:
    if col in new_data.columns:
        new_data[col] = new_data[col].astype(data_to_augment[col].dtype)

print("âœ… Synthetic Data Generated!")

# ==============================
# 5ï¸âƒ£  åˆå¹¶åˆæˆæ•°æ®å’ŒåŸå§‹æ•°æ®
# ==============================
augmented_data = pd.concat([data, new_data], ignore_index=True)

augmented_data.to_csv("augmented_data.csv", index=False)
