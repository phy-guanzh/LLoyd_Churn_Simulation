@inproceedings{inproceedings,
author = {Chan, Ka and Lenard, C. and Mills, Terence},
year = {2012},
month = {12},
pages = {},
title = {An Introduction to Markov Chains},
doi = {10.13140/2.1.1833.8248}
}

@article{BRADLEY19971145,
title = {The use of the area under the ROC curve in the evaluation of machine learning algorithms},
journal = {Pattern Recognition},
volume = {30},
number = {7},
pages = {1145-1159},
year = {1997},
issn = {0031-3203},
doi = {https://doi.org/10.1016/S0031-3203(96)00142-2},
url = {https://www.sciencedirect.com/science/article/pii/S0031320396001422},
author = {Andrew P. Bradley},
keywords = {The ROC curve, The area under the ROC curve (AUC), Accuracy measures, Cross-validation, Wilcoxon statistic, Standard error},
abstract = {In this paper we investigate the use of the area under the receiver operating characteristic (ROC) curve (AUC) as a performance measure for machine learning algorithms. As a case study we evaluate six machine learning algorithms (C4.5, Multiscale Classifier, Perceptron, Multi-layer Perceptron, k-Nearest Neighbours, and a Quadratic Discriminant Function) on six “real world” medical diagnostics data sets. We compare and discuss the use of AUC to the more conventional overall accuracy and find that AUC exhibits a number of desirable properties when compared to overall accuracy: increased sensitivity in Analysis of Variance (ANOVA) tests; a standard error that decreased as both AUC and the number of test samples increased; decision threshold independent; and it is invariant to a priori class probabilities. The paper concludes with the recommendation that AUC be used in preference to overall accuracy for “single number” evaluation of machine learning algorithms.}
}

@article{Nadarajah01092005,
author = {Saralees Nadarajah},
title = {A generalized normal distribution},
journal = {Journal of Applied Statistics},
volume = {32},
number = {7},
pages = {685--694},
year = {2005},
publisher = {Taylor \& Francis},
doi = {10.1080/02664760500079464},
URL = {   
        https://doi.org/10.1080/02664760500079464
},
eprint = {     
        https://doi.org/10.1080/02664760500079464
}
}



@misc{poslavskaya2023encodingcategoricaldatahotter,
      title={Encoding categorical data: Is there yet anything 'hotter' than one-hot encoding?}, 
      author={Ekaterina Poslavskaya and Alexey Korolev},
      year={2023},
      eprint={2312.16930},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.16930}, 
}

@article{student1908probable,
  title={The probable error of a mean},
  author={Student},
  journal={Biometrika},
  pages={1--25},
  year={1908},
  publisher={JSTOR}
}

@inproceedings{ctgan,
  title={Modeling Tabular data using Conditional GAN},
  author={Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{Chen_2016, series={KDD ’16},
   title={XGBoost: A Scalable Tree Boosting System},
   url={http://dx.doi.org/10.1145/2939672.2939785},
   DOI={10.1145/2939672.2939785},
   booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
   publisher={ACM},
   author={Chen, Tianqi and Guestrin, Carlos},
   year={2016},
   month=aug, pages={785–794},
   collection={KDD ’16} }


@article{correlation,
author = {Senthilnathan, Samithamby},
year = {2019},
month = {07},
pages = {},
title = {Usefulness of Correlation Analysis},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3416918}
}

@article{Pearson1900,
  doi = {10.1080/14786440009463897},
  url = {https://doi.org/10.1080/14786440009463897},
  year = {1900},
  month = jul,
  publisher = {Informa {UK} Limited},
  volume = {50},
  number = {302},
  pages = {157--175},
  author = {Karl Pearson},
  title = {X. On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling},
  journal = {The London,  Edinburgh,  and Dublin Philosophical Magazine and Journal of Science}
}

@Inbook{Tangwongsan2018,
author="Tangwongsan, Kanat
and Hirzel, Martin
and Schneider, Scott",
editor="Sakr, Sherif
and Zomaya, Albert",
title="Sliding-Window Aggregation Algorithms",
bookTitle="Encyclopedia of Big Data Technologies",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="1--6",
abstract="Sliding-window aggregation summarizes a collection of recent streaming data, capturing the most recent happenings as well as some history. Algorithms for this problem are required to maintain an aggregate value as new data items are inserted into the window when they arrive, and old data items are evicted from the window when they expire. Supporting this efficiently poses algorithmic challenges, especially for non-invertible aggregation functions such asmax, for which there is no way to ``subtract off'' expiring items. This chapter provides a brief overview of this area of research and explores a number of sliding-window aggregation algorithms, including both simple and sophisticated algorithms. Real-world use cases are also given to showcase problem scenarios where sliding-window aggregation can be applicable.",
isbn="978-3-319-63962-8",
doi="10.1007/978-3-319-63962-8_157-1",
url="https://doi.org/10.1007/978-3-319-63962-8_157-1"
}


@article{KDE,
author = {Weglarczyk, Stanislaw},
year = {2018},
month = {11},
pages = {00037},
title = {Kernel density estimation and its application},
volume = {23},
journal = {ITM Web of Conferences},
doi = {10.1051/itmconf/20182300037}
}

@misc{forage2025,
  author = "{The Forage}",
  title = "Lloyds Banking Group Data Science Simulation",
  year = "2025",
  url = "https://www.theforage.com/simulations/lloyds-banking-group/data-science-fpey",
  note = "Accessed: February 12, 2025"
}

@INPROCEEDINGS{8538420,
  author={Agrawal, Sanket and Das, Aditya and Gaikwad, Amit and Dhage, Sudhir},
  booktitle={2018 International Conference on Smart Computing and Electronic Enterprise (ICSCEE)}, 
  title={Customer Churn Prediction Modelling Based on Behavioural Patterns Analysis using Deep Learning}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  keywords={Predictive models;Companies;Feature extraction;Neural networks;Data models;Training;Churn Prediction;Deep Learning;ANN;Correlation Analysis},
  doi={10.1109/ICSCEE.2018.8538420}}
@inproceedings{Khan_2015,
   title={Behavioral Modeling for Churn Prediction: Early Indicators and Accurate Predictors of Custom Defection and Loyalty},
   url={http://dx.doi.org/10.1109/BigDataCongress.2015.107},
   DOI={10.1109/bigdatacongress.2015.107},
   booktitle={2015 IEEE International Congress on Big Data},
   publisher={IEEE},
   author={Khan, Muhammad Raza and Manoj, Joshua and Singh, Anikate and Blumenstock, Joshua},
   year={2015},
   month=jun, pages={677–680} }
